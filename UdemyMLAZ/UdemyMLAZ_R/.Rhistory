dataset = read.csv("D:/OneDrive/Courses - Labs/ML_AZ/Machine Learning A-Z/Part 1 - Data Preprocessing/Data.csv")
dataset$Age = ifelse(test = is.na(dataset$Age), ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)), dataset$Age)
dataset$Salary = ifelse(test = is.na(dataset$Salary), ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)), dataset$Salary)
dataset$Purchased = factor(dataset$Purchased, levels = c('No', 'Yes'), labels = c(0, 1))
dataset$Country = factor(dataset$Country, levels = c('France', 'Spain', 'Germany'), labels = c(1, 2, 3))
library(caTools) set.seed(seed = 123) split = sample.split(dataset$Purchased, SplitRatio = 0.8) training_set = subset(dataset, split == TRUE) test_set = subset(dataset, split == FALSE) #feature scaling training_set[, 2:3] = scale(training_set[, 2:3]) test_set[, 2:3] = scale(test_set[, 2:3])
dataset = read.csv("..\\Simple_Linear_Regression\\Salary_Data.csv")
dataset
# split the data library(caTools) set.seed(seed = 123) split = sample.split(dataset$Salary, SplitRatio = 2/3) training_set = subset(dataset, split == TRUE) test_set = subset(dataset, split == FALSE)
regressor = lm(formula = Salary ~ YearsExperience,training_set)
summary(regressor)
y_pred = predict(regressor,newdata = test_set)
y_pred
install.packages(ggplot2)
install.packages('ggplot2')
library(ggplot2)
ggplot() +     geom_point(         aes(x = training_set$YearsExperience, y = training_set$Salary),         color = 'red') +     geom_line(         aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),         color = 'green')
ggplot() +     geom_point(         aes(x = training_set$YearsExperience, y = training_set$Salary),         color = 'red') +     geom_line(         aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),         color = 'green') +     ggtitle('Salary vs Experience of Training Set') +     xlab('Years of Experience') +     ylab('Salary')
ggplot() +     geom_point(         aes(x = test_set$YearsExperience, y = test_set$Salary),         color = 'red') + #you don't change the prediction on the training set     geom_line(         aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),         color = 'green') +     ggtitle('Salary vs Experience of Training Set') +     xlab('Years of Experience') +     ylab('Salary')
dataset = read.csv("..\\Multiple_Linear_Regression\\5-_Startups.csv")
dataset = read.csv("..\\Multiple_Linear_Regression\\50_Startups.csv")
test_set = subset(dataset, split == FALSE)
dataset = read.csv("..\\Multiple_Linear_Regression\\50_Startups.csv")
dataset = read.csv("..\\Multiple_Linear_Regression\\50_Startups.csv")
dataset = read.csv("..\\Polynomial_Regression\\Position_Salaries.csv") dataset = dataset[2:3] # Splitting the dataset into the Training set and Test set # # install.packages('caTools') # library(caTools) # set.seed(123) # split = sample.split(dataset$Salary, SplitRatio = 2/3) # training_set = subset(dataset, split == TRUE) # test_set = subset(dataset, split == FALSE) # Feature Scaling # training_set = scale(training_set) # test_set = scale(test_set) # Fitting the SVR Model to the dataset # Create your regressor here #install.packages('e1071') library(e1071)
regressor = svm(formula = Salary ~ ., data = dataset)
regressor = svm(formula = Salary ~ ., data = dataset, type='eps-regression')
y_pred = predict(regressor, data.frame(Level = 6.5))
y_pred
library(ggplot2) ggplot() +   geom_point(aes(x = dataset$Level, y = dataset$Salary),              colour = 'red') +   geom_line(aes(x = dataset$Level, y = predict(regressor, newdata = dataset)),             colour = 'blue') +   ggtitle('Truth or Bluff (Regression Model)') +   xlab('Level') +   ylab('Salary')
install
install.packages('rpart')
dataset = read.csv("..\\Polynomial_Regression\\Position_Salaries.csv") dataset = dataset[2:3] # Splitting the dataset into the Training set and Test set # # install.packages('caTools') # library(caTools) # set.seed(123) # split = sample.split(dataset$Salary, SplitRatio = 2/3) # training_set = subset(dataset, split == TRUE) # test_set = subset(dataset, split == FALSE) # Feature Scaling # training_set = scale(training_set) # test_set = scale(test_set) # Fitting the SVR Model to the dataset # Create your regressor here #install.packages('e1071') library(rpart) regressor = rpart(formula = Salary ~ ., data = dataset, ) # Predicting a new result y_pred = predict(regressor, data.frame(Level = 6.5)) # Visualising the SVR Model results # install.packages('ggplot2') library(ggplot2) ggplot() +   geom_point(aes(x = dataset$Level, y = dataset$Salary),              colour = 'red') +   geom_line(aes(x = dataset$Level, y = predict(regressor, newdata = dataset)),             colour = 'blue') +   ggtitle('Truth or Bluff (Regression Model)') +   xlab('Level') +   ylab('Salary')
regressor = rpart(formula = Salary ~ ., data = dataset, control = rpart.control(minsplit = 1) ) # Predicting a new result y_pred = predict(regressor, data.frame(Level = 6.5)) # Visualising the SVR Model results # install.packages('ggplot2') library(ggplot2) ggplot() +   geom_point(aes(x = dataset$Level, y = dataset$Salary),              colour = 'red') +   geom_line(aes(x = dataset$Level, y = predict(regressor, newdata = dataset)),             colour = 'blue') +   ggtitle('Truth or Bluff (Regression Model)') +   xlab('Level') +   ylab('Salary')
library(ggplot2) x_grid = seq(min(dataset$Level), max(dataset$Level), 0.01) ggplot() +   geom_point(aes(x = dataset$Level, y = dataset$Salary),              colour = 'red') +   geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),             colour = 'blue') +   ggtitle('Truth or Bluff (Regression Model)') +   xlab('Level') +   ylab('Salary')
dataset = read.csv("..\\DecisionTree_Regression\\Position_Salaries.csv")
dataset
install
install.packages('randomForest')
dataset
dataset[1]
dataset$S
dataset$Salary
library(randomForest) set.seed(1234) regressor = randomForest(x = dataset[1], y = dataset$Salary, ntree = 10)
regressor
summary(regressor)
y_pred = predict(regressor, data.frame(Level = 6.5)) y_pred
library(ggplot2) x_grid = seq(min(dataset$Level), max(dataset$Level), 0.01) ggplot() +   geom_point(aes(x = dataset$Level, y = dataset$Salary),              colour = 'red') +   geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),             colour = 'blue') +   ggtitle('Truth or Bluff (Regression Model)') +   xlab('Level') +   ylab('Salary')
dataset = read.csv("..\\RandomForest_Regression\\Position_Salaries.csv") dataset = dataset[2:3] # fitting # install.packages('randomForest') library(randomForest) set.seed(1234) regressor = randomForest(x = dataset[1], y = dataset$Salary, ntree = 10)
library(ggplot2) x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1) ggplot() +   geom_point(aes(x = dataset$Level, y = dataset$Salary),              colour = 'red') +   geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),             colour = 'blue') +   ggtitle('Truth or Bluff (Regression Model)') +   xlab('Level') +   ylab('Salary')
library(randomForest) set.seed(1234) regressor = randomForest(x = dataset[1], y = dataset$Salary, ntree = 100)
library(ggplot2) x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1) ggplot() +   geom_point(aes(x = dataset$Level, y = dataset$Salary),              colour = 'red') +   geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),             colour = 'blue') +   ggtitle('Truth or Bluff (Regression Model)') +   xlab('Level') +   ylab('Salary')
library(randomForest) set.seed(1234) regressor = randomForest(x = dataset[1], y = dataset$Salary, ntree = 10)
y_pred = predict(regressor, data.frame(Level = 6.5))
y_pred
library(randomForest) set.seed(1234) regressor = randomForest(x = dataset[1], y = dataset$Salary, ntree = 100) summary(regressor) # Predicting a new result y_pred = predict(regressor, data.frame(Level = 6.5)) y_pred
library(ggplot2) x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1) ggplot() +   geom_point(aes(x = dataset$Level, y = dataset$Salary),              colour = 'red') +   geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),             colour = 'blue') +   ggtitle('Truth or Bluff (Regression Model)') +   xlab('Level') +   ylab('Salary')
library(randomForest) set.seed(1234) regressor = randomForest(x = dataset[1], y = dataset$Salary, ntree = 300) summary(regressor) # Predicting a new result y_pred = predict(regressor, data.frame(Level = 6.5)) y_pred
library(ggplot2) x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1) ggplot() +   geom_point(aes(x = dataset$Level, y = dataset$Salary),              colour = 'red') +   geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),             colour = 'blue') +   ggtitle('Truth or Bluff (Regression Model)') +   xlab('Level') +   ylab('Salary')
# Visualising the RF Model results (for higher resolution and smoother curve) # install.packages('ggplot2') library(ggplot2) x_grid = seq(min(dataset$Level), max(dataset$Level), 0.01) ggplot() +   geom_point(aes(x = dataset$Level, y = dataset$Salary),              colour = 'red') +   geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),             colour = 'blue') +   ggtitle('Truth or Bluff (Regression Model)') +   xlab('Level') +   ylab('Salary')
source("~/GitHub/ml_course-udemy/UdemyMLAZ/UdemyMLAZ_R/07-randomforest-regression.R", encoding = "Windows-1252")
source("~/GitHub/ml_course-udemy/UdemyMLAZ/UdemyMLAZ_R/06-decisiontree-regression.R", encoding = "Windows-1252")
dataset = read.csv("..\\RandomForest_Regression\\Position_Salaries.csv") dataset = dataset[2:3] # fitting # install.packages('randomForest') library(randomForest) set.seed(1234) regressor = randomForest(x = dataset[1], y = dataset$Salary, ntree = 300) summary(regressor) # Predicting a new result y_pred = predict(regressor, data.frame(Level = 6.5)) y_pred # Visualising the RF Model results (for higher resolution and smoother curve) # install.packages('ggplot2') library(ggplot2) x_grid = seq(min(dataset$Level), max(dataset$Level), 0.01) ggplot() +   geom_point(aes(x = dataset$Level, y = dataset$Salary),              colour = 'red') +   geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),             colour = 'blue') +   ggtitle('Truth or Bluff (Regression Model)') +   xlab('Level') +   ylab('Salary')
summary(regressor)
dataset = read.csv("..\\Simple_Linear_Regression\\Salary_Data.csv") # split the data library(caTools) set.seed(seed = 123) split = sample.split(dataset$Salary, SplitRatio = 2/3) training_set = subset(dataset, split == TRUE) test_set = subset(dataset, split == FALSE) #fit data using linear regression regressor = lm(formula = Salary ~ YearsExperience, training_set) #notice the stars indicating statistically significant models summary(regressor) # prepare predictions vector y_pred = predict(regressor, newdata = test_set) #let's plot data #install.packages('ggplot2') library(ggplot2) #plot observation points on training set ggplot() +     geom_point(         aes(x = training_set$YearsExperience, y = training_set$Salary),         color = 'red') +     geom_line(         aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),         color = 'green') +     ggtitle('Salary vs Experience of Training Set') +     xlab('Years of Experience') +     ylab('Salary') #plot observation points on test set ggplot() +     geom_point(         aes(x = test_set$YearsExperience, y = test_set$Salary),         color = 'red') + #you don't change the prediction on the training set     geom_line(         aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),         color = 'green') +     ggtitle('Salary vs Experience of Training Set') +     xlab('Years of Experience') +     ylab('Salary')
dataset = read.csv("..\\LogisticRegression\\Social_Network_Ads.csv")
dataset
library(caTools) set.seed(123) split = sample.split(dataset$Purchased, SplitRatio = 0.8) training_set = subset(dataset, split == TRUE) test_set = subset(dataset, split == FALSE)
dataset = dataset[2:3]
dataset
dataset = read.csv("..\\LogisticRegression\\Social_Network_Ads.csv") library(caTools) set.seed(123) split = sample.split(dataset$Purchased, SplitRatio = 0.8) training_set = subset(dataset, split == TRUE) test_set = subset(dataset, split == FALSE)
dataset
dataset = dataset[,3:5]
dataset
dataset = read.csv("..\\LogisticRegression\\Social_Network_Ads.csv") #select only age and salary and purahcaes dataset = dataset[, 3:5] library(caTools) set.seed(123) split = sample.split(dataset$Purchased, SplitRatio = 0.8) training_set = subset(dataset, split == TRUE) test_set = subset(dataset, split == FALSE)
training_set[, 1:2] = scale(training_set[, 1:2]) test_set[,1:2] = scale(test_set[,1:2])
prob_pred = predict(classifier, type = 'response', newdata = test_set[-3])
#fitting logistic regression to training set classifier = glm(formula = Purchased ~ ., family = binomial, data = training_set) #predicting test set results prob_pred = predict(classifier, type = 'response', newdata = test_set[-3])
prob_pred
y_pred = ifelse(prob_pred > 0.5, 1, 0)
cm = table(test_set[,3], y_pred)
cm
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
     main = 'Logistic Regression (Training set)',
     xlab = 'Age', ylab = 'Estimated Salary',
     xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
     main = 'Logistic Regression (Training set)',
     xlab = 'Age', ylab = 'Estimated Salary',
     xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
 library(ElemStatLearn)
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
     main = 'Logistic Regression (Test set)',
     xlab = 'Age', ylab = 'Estimated Salary',
     xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
